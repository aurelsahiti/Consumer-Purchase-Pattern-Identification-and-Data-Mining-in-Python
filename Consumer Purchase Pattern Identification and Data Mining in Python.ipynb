{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15e025a",
   "metadata": {},
   "source": [
    "# Comparison of Priori and Brute Force Algorithms for Frequent Items Mining\n",
    "## Midterm Project\n",
    "### Aurel Sahiti \n",
    "### UCID: as4579\n",
    "### as4579@njit.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794687c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96366a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e42ce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45b103",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "### This document details the implementation and comparison of two algorithms: the Priori algorithm and the Brute Force method for mining frequent item sets and generating association rules from transaction data. We will explore how both methods work and compare their performance based on their execution times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6965fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8850d5c",
   "metadata": {},
   "source": [
    "# Creating Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3866e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 30 items from supermarkets\n",
    "items = [\n",
    "    'milk', 'bread', 'butter', 'eggs', 'cheese', 'chicken', 'beef', 'fish', \n",
    "    'apples', 'bananas', 'oranges', 'grapes', 'cereal', 'pasta', 'rice', \n",
    "    'tomatoes', 'onions', 'potatoes', 'broccoli', 'carrots', 'shampoo', \n",
    "    'floss', 'toothpaste', 'detergent', 'cleaning_wipes', 'diapers', \n",
    "    'napkins', 'paper_towels', 'dish_soap', 'toilet_paper'\n",
    "]\n",
    "\n",
    "# Create a function that will generate random transactions\n",
    "def generate_transactions(num_transactions=20):\n",
    "    transactions = []\n",
    "    for _ in range(num_transactions):\n",
    "        # Randomly choose a subset of items for each transaction (1-10 items)\n",
    "        num_items = random.randint(1, 10)\n",
    "        transaction = random.sample(items, num_items)\n",
    "        transactions.append(transaction)\n",
    "    return transactions\n",
    "\n",
    "# Generate 5 databases with 20 transactions each\n",
    "databases = [generate_transactions() for _ in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ebcad",
   "metadata": {},
   "source": [
    "### - We started by defining 30 items commonly purchased in supermarkets.\n",
    "### - The “generate_transactions” function generates a list of transactions, where each transaction contains anywhere from 1 up to 10 items.\n",
    "### - In total, 5 databases were created with 20 transactions in each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c9e52",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c8390",
   "metadata": {},
   "source": [
    "# Creating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dacecc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate support for a given itemset\n",
    "def calculate_support(itemset, transactions):\n",
    "    count = sum(1 for transaction in transactions if itemset.issubset(transaction))\n",
    "    return count / len(transactions)\n",
    "\n",
    "# Filter itemsets by support\n",
    "def filter_itemsets_by_support(itemsets, transactions, min_support):\n",
    "    filtered_itemsets = {}\n",
    "    for itemset in itemsets:\n",
    "        support = calculate_support(itemset, transactions)\n",
    "        if support >= min_support:\n",
    "            filtered_itemsets[itemset] = support\n",
    "    return filtered_itemsets\n",
    "\n",
    "# Generate candidate itemsets of size 1\n",
    "def get_itemsets_size_1(transactions):\n",
    "    itemset = set()\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            itemset.add(frozenset([item]))\n",
    "    return itemset\n",
    "\n",
    "# Generate candidate itemsets of larger size by combining frequent itemsets\n",
    "def generate_candidate_itemsets(frequent_itemsets, k):\n",
    "    candidates = set()\n",
    "    frequent_itemsets_list = list(frequent_itemsets)\n",
    "    \n",
    "    for i in range(len(frequent_itemsets_list)):\n",
    "        for j in range(i + 1, len(frequent_itemsets_list)):\n",
    "            l1 = list(frequent_itemsets_list[i])\n",
    "            l2 = list(frequent_itemsets_list[j])\n",
    "            l1.sort()\n",
    "            l2.sort()\n",
    "            if l1[:k - 2] == l2[:k - 2]:  # Only combine if first k-2 items are the same\n",
    "                candidates.add(frozenset(frequent_itemsets_list[i] | frequent_itemsets_list[j]))\n",
    "                \n",
    "    return candidates\n",
    "\n",
    "# Generate association rules\n",
    "def generate_association_rules(frequent_itemsets, transactions, min_confidence):\n",
    "    rules = []\n",
    "    \n",
    "    for itemset in frequent_itemsets:\n",
    "        if len(itemset) < 2:\n",
    "            continue\n",
    "        for consequence in itemset:\n",
    "            antecedent = itemset - frozenset([consequence])\n",
    "            if len(antecedent) == 0:\n",
    "                continue\n",
    "            # Calculate confidence\n",
    "            support_itemset = calculate_support(itemset, transactions)\n",
    "            support_antecedent = calculate_support(antecedent, transactions)\n",
    "            confidence = support_itemset / support_antecedent if support_antecedent > 0 else 0\n",
    "            \n",
    "            if confidence >= min_confidence:\n",
    "                rules.append((antecedent, frozenset([consequence]), confidence))\n",
    "    \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083a631",
   "metadata": {},
   "source": [
    "### - Support is calculated as the fraction of transactions containing the given item-set.\n",
    "### - The “calculate_support” function is used in both algorithms to check if an item-set is frequent (if its support is above the specified minimum threshold).\n",
    "### - The “filter_itemsets_by_support” function loops through each item-set in the input “itemsets”. For each item-set, it calculates its support using the “calculate_support” function. If the support is greater than or equal to the specified “min_support”, the item-set is added to the “filtered_itemsets” dictionary along with its support value. Finally, the function returns the filtered_itemsets dictionary, which contains only itemsets that meet the minimum support criteria.\n",
    "### - The “get_itemsets_size_1” function is created to generate the initial set of 1-itemsets (combinations of single items) from a list of transactions.\n",
    "### - The use of the “frozenset” ensures that the itemsets are immutable, which is useful when storing these itemsets as keys in a dictionary for support calculations or when further processing them to generate larger itemsets.\n",
    "### - The “generate_candidate_itemsets” function generates candidate itemsets of size “k” by combining frequent itemsets of size k-1.\n",
    "### - The “generate_association_rules” function generates association rules from frequent item-sets by calculating the confidence of each rule (based on the support of the item-set and its antecedent).\n",
    "### - It also checks if the confidence meets the specified minimum threshold and stores the rules that satisfy that condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d142b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91ad66",
   "metadata": {},
   "source": [
    "# Apriori Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a43616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Apriori algorithm\n",
    "def apriori(transactions, items, min_support=0.2, min_confidence=0.6):\n",
    "    # Step 1: Generate itemsets of size 1\n",
    "    candidate_itemsets = get_itemsets_size_1(transactions)\n",
    "    \n",
    "    # Step 2: Filter itemsets by support\n",
    "    frequent_itemsets = filter_itemsets_by_support(candidate_itemsets, transactions, min_support)\n",
    "    \n",
    "    all_frequent_itemsets = dict(frequent_itemsets)\n",
    "    \n",
    "    k = 2\n",
    "    while frequent_itemsets:\n",
    "        # Step 3: Generate candidate itemsets of size k\n",
    "        candidate_itemsets = generate_candidate_itemsets(frequent_itemsets, k)\n",
    "        \n",
    "        # Step 4: Filter itemsets by support\n",
    "        frequent_itemsets = filter_itemsets_by_support(candidate_itemsets, transactions, min_support)\n",
    "        \n",
    "        all_frequent_itemsets.update(frequent_itemsets)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    # Step 5: Generate association rules\n",
    "    rules = generate_association_rules(all_frequent_itemsets.keys(), transactions, min_confidence)\n",
    "    \n",
    "    return all_frequent_itemsets, rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e03b4f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database 1:\n",
      "\n",
      "Apriori Frequent Itemsets:\n",
      "Itemset: {'rice'}, Support: 0.2000\n",
      "Itemset: {'butter'}, Support: 0.2000\n",
      "Itemset: {'chicken'}, Support: 0.2000\n",
      "Itemset: {'cleaning_wipes'}, Support: 0.3000\n",
      "Itemset: {'onions'}, Support: 0.2000\n",
      "Itemset: {'eggs'}, Support: 0.2000\n",
      "Itemset: {'carrots'}, Support: 0.2500\n",
      "Itemset: {'detergent'}, Support: 0.3500\n",
      "Itemset: {'grapes'}, Support: 0.3500\n",
      "Itemset: {'milk'}, Support: 0.2000\n",
      "Itemset: {'bananas'}, Support: 0.3000\n",
      "Itemset: {'oranges'}, Support: 0.2000\n",
      "Itemset: {'floss'}, Support: 0.2500\n",
      "Itemset: {'broccoli'}, Support: 0.2500\n",
      "Itemset: {'dish_soap'}, Support: 0.2000\n",
      "Itemset: {'tomatoes'}, Support: 0.3000\n",
      "Itemset: {'detergent', 'grapes'}, Support: 0.2500\n",
      "Itemset: {'chicken', 'grapes'}, Support: 0.2000\n",
      "Itemset: {'cleaning_wipes', 'milk'}, Support: 0.2000\n",
      "\n",
      "Apriori Association Rules:\n",
      "Rule: {'grapes'} -> {'detergent'}, Confidence: 0.7143\n",
      "Rule: {'detergent'} -> {'grapes'}, Confidence: 0.7143\n",
      "Rule: {'chicken'} -> {'grapes'}, Confidence: 1.0000\n",
      "Rule: {'milk'} -> {'cleaning_wipes'}, Confidence: 1.0000\n",
      "Rule: {'cleaning_wipes'} -> {'milk'}, Confidence: 0.6667\n",
      "\n",
      "Database 2:\n",
      "\n",
      "Apriori Frequent Itemsets:\n",
      "Itemset: {'beef'}, Support: 0.2000\n",
      "Itemset: {'cereal'}, Support: 0.2000\n",
      "Itemset: {'apples'}, Support: 0.2500\n",
      "Itemset: {'onions'}, Support: 0.2000\n",
      "Itemset: {'eggs'}, Support: 0.4000\n",
      "Itemset: {'bread'}, Support: 0.3000\n",
      "Itemset: {'detergent'}, Support: 0.2000\n",
      "Itemset: {'oranges'}, Support: 0.2500\n",
      "Itemset: {'broccoli'}, Support: 0.3000\n",
      "Itemset: {'napkins'}, Support: 0.2500\n",
      "Itemset: {'tomatoes'}, Support: 0.2000\n",
      "Itemset: {'shampoo'}, Support: 0.2500\n",
      "Itemset: {'toilet_paper'}, Support: 0.2000\n",
      "\n",
      "Apriori Association Rules:\n",
      "\n",
      "Database 3:\n",
      "\n",
      "Apriori Frequent Itemsets:\n",
      "Itemset: {'rice'}, Support: 0.2000\n",
      "Itemset: {'butter'}, Support: 0.2500\n",
      "Itemset: {'cleaning_wipes'}, Support: 0.2500\n",
      "Itemset: {'cereal'}, Support: 0.2000\n",
      "Itemset: {'diapers'}, Support: 0.2000\n",
      "Itemset: {'apples'}, Support: 0.3000\n",
      "Itemset: {'onions'}, Support: 0.2500\n",
      "Itemset: {'eggs'}, Support: 0.3500\n",
      "Itemset: {'pasta'}, Support: 0.2500\n",
      "Itemset: {'detergent'}, Support: 0.2000\n",
      "Itemset: {'paper_towels'}, Support: 0.2000\n",
      "Itemset: {'grapes'}, Support: 0.3500\n",
      "Itemset: {'milk'}, Support: 0.2000\n",
      "Itemset: {'bananas'}, Support: 0.3500\n",
      "Itemset: {'toothpaste'}, Support: 0.2000\n",
      "Itemset: {'oranges'}, Support: 0.2000\n",
      "Itemset: {'broccoli'}, Support: 0.2000\n",
      "Itemset: {'napkins'}, Support: 0.2500\n",
      "Itemset: {'fish'}, Support: 0.2500\n",
      "Itemset: {'potatoes'}, Support: 0.2500\n",
      "Itemset: {'toilet_paper'}, Support: 0.2500\n",
      "Itemset: {'diapers', 'bananas'}, Support: 0.2000\n",
      "Itemset: {'grapes', 'bananas'}, Support: 0.2000\n",
      "\n",
      "Apriori Association Rules:\n",
      "Rule: {'diapers'} -> {'bananas'}, Confidence: 1.0000\n",
      "\n",
      "Database 4:\n",
      "\n",
      "Apriori Frequent Itemsets:\n",
      "Itemset: {'beef'}, Support: 0.3000\n",
      "Itemset: {'butter'}, Support: 0.2000\n",
      "Itemset: {'cereal'}, Support: 0.2000\n",
      "Itemset: {'diapers'}, Support: 0.2500\n",
      "Itemset: {'apples'}, Support: 0.3000\n",
      "Itemset: {'pasta'}, Support: 0.2000\n",
      "Itemset: {'grapes'}, Support: 0.3000\n",
      "Itemset: {'bananas'}, Support: 0.2000\n",
      "Itemset: {'toothpaste'}, Support: 0.2500\n",
      "Itemset: {'floss'}, Support: 0.2500\n",
      "Itemset: {'napkins'}, Support: 0.3000\n",
      "Itemset: {'fish'}, Support: 0.2500\n",
      "Itemset: {'potatoes'}, Support: 0.2500\n",
      "Itemset: {'toilet_paper'}, Support: 0.2000\n",
      "\n",
      "Apriori Association Rules:\n",
      "\n",
      "Database 5:\n",
      "\n",
      "Apriori Frequent Itemsets:\n",
      "Itemset: {'butter'}, Support: 0.2000\n",
      "Itemset: {'cleaning_wipes'}, Support: 0.3500\n",
      "Itemset: {'diapers'}, Support: 0.2000\n",
      "Itemset: {'apples'}, Support: 0.4000\n",
      "Itemset: {'onions'}, Support: 0.3500\n",
      "Itemset: {'eggs'}, Support: 0.2500\n",
      "Itemset: {'carrots'}, Support: 0.3000\n",
      "Itemset: {'bread'}, Support: 0.2000\n",
      "Itemset: {'paper_towels'}, Support: 0.2000\n",
      "Itemset: {'milk'}, Support: 0.3000\n",
      "Itemset: {'bananas'}, Support: 0.2500\n",
      "Itemset: {'toothpaste'}, Support: 0.3000\n",
      "Itemset: {'oranges'}, Support: 0.2500\n",
      "Itemset: {'floss'}, Support: 0.3000\n",
      "Itemset: {'broccoli'}, Support: 0.4000\n",
      "Itemset: {'napkins'}, Support: 0.2000\n",
      "Itemset: {'dish_soap'}, Support: 0.2500\n",
      "Itemset: {'shampoo'}, Support: 0.3000\n",
      "Itemset: {'potatoes'}, Support: 0.2500\n",
      "Itemset: {'broccoli', 'dish_soap'}, Support: 0.2000\n",
      "Itemset: {'shampoo', 'potatoes'}, Support: 0.2000\n",
      "Itemset: {'apples', 'broccoli'}, Support: 0.2000\n",
      "Itemset: {'broccoli', 'milk'}, Support: 0.2000\n",
      "Itemset: {'apples', 'toothpaste'}, Support: 0.2000\n",
      "Itemset: {'broccoli', 'eggs'}, Support: 0.2000\n",
      "Itemset: {'cleaning_wipes', 'milk'}, Support: 0.2000\n",
      "Itemset: {'shampoo', 'onions'}, Support: 0.2000\n",
      "\n",
      "Apriori Association Rules:\n",
      "Rule: {'dish_soap'} -> {'broccoli'}, Confidence: 0.8000\n",
      "Rule: {'potatoes'} -> {'shampoo'}, Confidence: 0.8000\n",
      "Rule: {'shampoo'} -> {'potatoes'}, Confidence: 0.6667\n",
      "Rule: {'milk'} -> {'broccoli'}, Confidence: 0.6667\n",
      "Rule: {'toothpaste'} -> {'apples'}, Confidence: 0.6667\n",
      "Rule: {'eggs'} -> {'broccoli'}, Confidence: 0.8000\n",
      "Rule: {'milk'} -> {'cleaning_wipes'}, Confidence: 0.6667\n",
      "Rule: {'shampoo'} -> {'onions'}, Confidence: 0.6667\n"
     ]
    }
   ],
   "source": [
    "# Apriori results\n",
    "def apriori_results(databases, min_support, min_confidence, items):\n",
    "    for i, transactions in enumerate(databases):\n",
    "        print(f\"\\nDatabase {i + 1}:\")\n",
    "        \n",
    "        # Apriori\n",
    "        start_time = time.time()\n",
    "        frequent_itemsets_apriori, rules_apriori = apriori(transactions, items, min_support, min_confidence)\n",
    "        apriori_time = time.time() - start_time\n",
    "\n",
    "        # Output frequent itemsets from Apriori\n",
    "        print(\"\\nApriori Frequent Itemsets:\")\n",
    "        for itemset, support in frequent_itemsets_apriori.items():\n",
    "            print(f\"Itemset: {set(itemset)}, Support: {support:.4f}\")\n",
    "        \n",
    "        # Output association rules from Apriori\n",
    "        print(\"\\nApriori Association Rules:\")\n",
    "        for antecedent, consequent, confidence in rules_apriori:\n",
    "            print(f\"Rule: {set(antecedent)} -> {set(consequent)}, Confidence: {confidence:.4f}\")\n",
    "        \n",
    "\n",
    "# Set minimum support and confidence\n",
    "min_support = 0.2\n",
    "min_confidence = 0.6\n",
    "\n",
    "# Compare the two algorithms on all 5 databases\n",
    "apriori_results(databases, min_support, min_confidence, items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48fb34e",
   "metadata": {},
   "source": [
    "### - The Apriori algorithm works by generating candidate itemsets of size 1, then iteratively combining frequent itemsets to form larger itemsets.\n",
    "### - After generating itemsets, it filters them based on the minimum support.\n",
    "### - Once all frequent itemsets are found, it generates association rules by calculating their confidence and comparing it to the minimum confidence threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51b1a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da10026",
   "metadata": {},
   "source": [
    "# Brute Force Method Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfae1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Brute Force Method\n",
    "# Brute force method for finding frequent itemsets\n",
    "def brute_force(transactions, min_support=0.2, min_confidence=0.6):\n",
    "    transactions = list(map(set, transactions))  # Convert transactions to sets\n",
    "    all_frequent_itemsets = {}  # To store all frequent itemsets\n",
    "    k = 1  # Start with 1-itemsets\n",
    "    \n",
    "    while True:\n",
    "        # Step 1: Generate all possible k-itemsets\n",
    "        items_in_transactions = set(item for transaction in transactions for item in transaction)\n",
    "        candidate_itemsets = list(combinations(items_in_transactions, k))\n",
    "        \n",
    "        # Step 2: Filter itemsets by support\n",
    "        frequent_itemsets = {}\n",
    "        for itemset in candidate_itemsets:\n",
    "            itemset = frozenset(itemset)\n",
    "            support = calculate_support(itemset, transactions)\n",
    "            if support >= min_support:\n",
    "                frequent_itemsets[itemset] = support\n",
    "        \n",
    "        # Step 3: Terminate if no frequent itemsets found\n",
    "        if not frequent_itemsets:\n",
    "            break\n",
    "        \n",
    "        # Add to all frequent itemsets\n",
    "        all_frequent_itemsets.update(frequent_itemsets)\n",
    "        k += 1  # Increase the size of the itemset\n",
    "        \n",
    "    \n",
    "    return all_frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c0ef4f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database 1:\n",
      "\n",
      "Brute Frequent Itemsets:\n",
      "Itemset: {'detergent'}, Support: 0.3500\n",
      "Itemset: {'carrots'}, Support: 0.2500\n",
      "Itemset: {'grapes'}, Support: 0.3500\n",
      "Itemset: {'butter'}, Support: 0.2000\n",
      "Itemset: {'floss'}, Support: 0.2500\n",
      "Itemset: {'eggs'}, Support: 0.2000\n",
      "Itemset: {'tomatoes'}, Support: 0.3000\n",
      "Itemset: {'chicken'}, Support: 0.2000\n",
      "Itemset: {'rice'}, Support: 0.2000\n",
      "Itemset: {'broccoli'}, Support: 0.2500\n",
      "Itemset: {'onions'}, Support: 0.2000\n",
      "Itemset: {'dish_soap'}, Support: 0.2000\n",
      "Itemset: {'cleaning_wipes'}, Support: 0.3000\n",
      "Itemset: {'oranges'}, Support: 0.2000\n",
      "Itemset: {'bananas'}, Support: 0.3000\n",
      "Itemset: {'milk'}, Support: 0.2000\n",
      "Itemset: {'detergent', 'grapes'}, Support: 0.2500\n",
      "Itemset: {'chicken', 'grapes'}, Support: 0.2000\n",
      "Itemset: {'cleaning_wipes', 'milk'}, Support: 0.2000\n",
      "\n",
      "Brute Force Association Rules:\n",
      "Rule: {'grapes'} -> {'detergent'}, Confidence: 0.7143\n",
      "Rule: {'detergent'} -> {'grapes'}, Confidence: 0.7143\n",
      "Rule: {'chicken'} -> {'grapes'}, Confidence: 1.0000\n",
      "Rule: {'milk'} -> {'cleaning_wipes'}, Confidence: 1.0000\n",
      "Rule: {'cleaning_wipes'} -> {'milk'}, Confidence: 0.6667\n",
      "\n",
      "Database 2:\n",
      "\n",
      "Brute Frequent Itemsets:\n",
      "Itemset: {'apples'}, Support: 0.2500\n",
      "Itemset: {'detergent'}, Support: 0.2000\n",
      "Itemset: {'cereal'}, Support: 0.2000\n",
      "Itemset: {'eggs'}, Support: 0.4000\n",
      "Itemset: {'tomatoes'}, Support: 0.2000\n",
      "Itemset: {'beef'}, Support: 0.2000\n",
      "Itemset: {'toilet_paper'}, Support: 0.2000\n",
      "Itemset: {'broccoli'}, Support: 0.3000\n",
      "Itemset: {'onions'}, Support: 0.2000\n",
      "Itemset: {'napkins'}, Support: 0.2500\n",
      "Itemset: {'shampoo'}, Support: 0.2500\n",
      "Itemset: {'oranges'}, Support: 0.2500\n",
      "Itemset: {'bread'}, Support: 0.3000\n",
      "\n",
      "Brute Force Association Rules:\n",
      "\n",
      "Database 3:\n",
      "\n",
      "Brute Frequent Itemsets:\n",
      "Itemset: {'detergent'}, Support: 0.2000\n",
      "Itemset: {'apples'}, Support: 0.3000\n",
      "Itemset: {'potatoes'}, Support: 0.2500\n",
      "Itemset: {'grapes'}, Support: 0.3500\n",
      "Itemset: {'butter'}, Support: 0.2500\n",
      "Itemset: {'toothpaste'}, Support: 0.2000\n",
      "Itemset: {'cereal'}, Support: 0.2000\n",
      "Itemset: {'eggs'}, Support: 0.3500\n",
      "Itemset: {'pasta'}, Support: 0.2500\n",
      "Itemset: {'toilet_paper'}, Support: 0.2500\n",
      "Itemset: {'paper_towels'}, Support: 0.2000\n",
      "Itemset: {'fish'}, Support: 0.2500\n",
      "Itemset: {'rice'}, Support: 0.2000\n",
      "Itemset: {'broccoli'}, Support: 0.2000\n",
      "Itemset: {'onions'}, Support: 0.2500\n",
      "Itemset: {'napkins'}, Support: 0.2500\n",
      "Itemset: {'cleaning_wipes'}, Support: 0.2500\n",
      "Itemset: {'oranges'}, Support: 0.2000\n",
      "Itemset: {'diapers'}, Support: 0.2000\n",
      "Itemset: {'bananas'}, Support: 0.3500\n",
      "Itemset: {'milk'}, Support: 0.2000\n",
      "Itemset: {'grapes', 'bananas'}, Support: 0.2000\n",
      "Itemset: {'diapers', 'bananas'}, Support: 0.2000\n",
      "\n",
      "Brute Force Association Rules:\n",
      "Rule: {'diapers'} -> {'bananas'}, Confidence: 1.0000\n",
      "\n",
      "Database 4:\n",
      "\n",
      "Brute Frequent Itemsets:\n",
      "Itemset: {'apples'}, Support: 0.3000\n",
      "Itemset: {'potatoes'}, Support: 0.2500\n",
      "Itemset: {'grapes'}, Support: 0.3000\n",
      "Itemset: {'butter'}, Support: 0.2000\n",
      "Itemset: {'floss'}, Support: 0.2500\n",
      "Itemset: {'toothpaste'}, Support: 0.2500\n",
      "Itemset: {'cereal'}, Support: 0.2000\n",
      "Itemset: {'pasta'}, Support: 0.2000\n",
      "Itemset: {'beef'}, Support: 0.3000\n",
      "Itemset: {'toilet_paper'}, Support: 0.2000\n",
      "Itemset: {'fish'}, Support: 0.2500\n",
      "Itemset: {'napkins'}, Support: 0.3000\n",
      "Itemset: {'diapers'}, Support: 0.2500\n",
      "Itemset: {'bananas'}, Support: 0.2000\n",
      "\n",
      "Brute Force Association Rules:\n",
      "\n",
      "Database 5:\n",
      "\n",
      "Brute Frequent Itemsets:\n",
      "Itemset: {'apples'}, Support: 0.4000\n",
      "Itemset: {'potatoes'}, Support: 0.2500\n",
      "Itemset: {'carrots'}, Support: 0.3000\n",
      "Itemset: {'butter'}, Support: 0.2000\n",
      "Itemset: {'floss'}, Support: 0.3000\n",
      "Itemset: {'toothpaste'}, Support: 0.3000\n",
      "Itemset: {'eggs'}, Support: 0.2500\n",
      "Itemset: {'paper_towels'}, Support: 0.2000\n",
      "Itemset: {'broccoli'}, Support: 0.4000\n",
      "Itemset: {'onions'}, Support: 0.3500\n",
      "Itemset: {'dish_soap'}, Support: 0.2500\n",
      "Itemset: {'napkins'}, Support: 0.2000\n",
      "Itemset: {'shampoo'}, Support: 0.3000\n",
      "Itemset: {'cleaning_wipes'}, Support: 0.3500\n",
      "Itemset: {'oranges'}, Support: 0.2500\n",
      "Itemset: {'bread'}, Support: 0.2000\n",
      "Itemset: {'diapers'}, Support: 0.2000\n",
      "Itemset: {'bananas'}, Support: 0.2500\n",
      "Itemset: {'milk'}, Support: 0.3000\n",
      "Itemset: {'apples', 'toothpaste'}, Support: 0.2000\n",
      "Itemset: {'apples', 'broccoli'}, Support: 0.2000\n",
      "Itemset: {'potatoes', 'shampoo'}, Support: 0.2000\n",
      "Itemset: {'broccoli', 'eggs'}, Support: 0.2000\n",
      "Itemset: {'broccoli', 'dish_soap'}, Support: 0.2000\n",
      "Itemset: {'broccoli', 'milk'}, Support: 0.2000\n",
      "Itemset: {'shampoo', 'onions'}, Support: 0.2000\n",
      "Itemset: {'cleaning_wipes', 'milk'}, Support: 0.2000\n",
      "\n",
      "Brute Force Association Rules:\n",
      "Rule: {'toothpaste'} -> {'apples'}, Confidence: 0.6667\n",
      "Rule: {'shampoo'} -> {'potatoes'}, Confidence: 0.6667\n",
      "Rule: {'potatoes'} -> {'shampoo'}, Confidence: 0.8000\n",
      "Rule: {'eggs'} -> {'broccoli'}, Confidence: 0.8000\n",
      "Rule: {'dish_soap'} -> {'broccoli'}, Confidence: 0.8000\n",
      "Rule: {'milk'} -> {'broccoli'}, Confidence: 0.6667\n",
      "Rule: {'shampoo'} -> {'onions'}, Confidence: 0.6667\n",
      "Rule: {'milk'} -> {'cleaning_wipes'}, Confidence: 0.6667\n"
     ]
    }
   ],
   "source": [
    "# Brute Force results\n",
    "def brute_results(databases, min_support, min_confidence, items):\n",
    "    for i, transactions in enumerate(databases):\n",
    "        print(f\"\\nDatabase {i + 1}:\")\n",
    "        \n",
    "        # Brute Force\n",
    "        start_time = time.time()\n",
    "        frequent_itemsets_brute = brute_force(transactions, min_support)\n",
    "        brute_time = time.time() - start_time\n",
    "\n",
    "        # Output frequent itemsets from Brute\n",
    "        print(\"\\nBrute Frequent Itemsets:\")\n",
    "        for itemset, support in frequent_itemsets_brute.items():\n",
    "            print(f\"Itemset: {set(itemset)}, Support: {support:.4f}\")\n",
    "        \n",
    "        # Generate and output association rules from Brute\n",
    "        print(\"\\nBrute Force Association Rules:\")\n",
    "        rules_bruteforce = generate_association_rules(frequent_itemsets_brute.keys(), transactions, min_confidence)\n",
    "        for antecedent, consequent, confidence in rules_bruteforce:\n",
    "            print(f\"Rule: {set(antecedent)} -> {set(consequent)}, Confidence: {confidence:.4f}\")\n",
    "        \n",
    "        \n",
    "# Set minimum support and confidence\n",
    "min_support = 0.2\n",
    "min_confidence = 0.6\n",
    "\n",
    "# Compare the two algorithms on all 5 databases\n",
    "brute_results(databases, min_support, min_confidence, items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1514d3f8",
   "metadata": {},
   "source": [
    "### - The Brute Force method generates all possible itemsets of increasing size (starting from size 1).\n",
    "### - It filters itemsets based on support but does not use any optimizations (like Apriori) to limit the number of candidate itemsets. This results in a much higher computational cost.\n",
    "### - The following function takes the results and prints for each database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929f78a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24469634",
   "metadata": {},
   "source": [
    "# Comparison of Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab2b273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison for Database 1:\n",
      "Apriori Association Rules Count: 5, Time: 0.001103 seconds\n",
      "Brute Force Association Rules Count: 5, Time: 0.011115 seconds\n",
      "\n",
      "Comparison for Database 2:\n",
      "Apriori Association Rules Count: 0, Time: 0.000779 seconds\n",
      "Brute Force Association Rules Count: 0, Time: 0.000789 seconds\n",
      "\n",
      "Comparison for Database 3:\n",
      "Apriori Association Rules Count: 1, Time: 0.001988 seconds\n",
      "Brute Force Association Rules Count: 1, Time: 0.009172 seconds\n",
      "\n",
      "Comparison for Database 4:\n",
      "Apriori Association Rules Count: 0, Time: 0.000917 seconds\n",
      "Brute Force Association Rules Count: 0, Time: 0.000914 seconds\n",
      "\n",
      "Comparison for Database 5:\n",
      "Apriori Association Rules Count: 8, Time: 0.001774 seconds\n",
      "Brute Force Association Rules Count: 8, Time: 0.006785 seconds\n"
     ]
    }
   ],
   "source": [
    "# Comparing brute force and apriori\n",
    "def compare_algorithms(databases, min_support, min_confidence, items):\n",
    "    for i, transactions in enumerate(databases):\n",
    "        print(f\"\\nComparison for Database {i + 1}:\")\n",
    "        \n",
    "        # Apriori method\n",
    "        start_time = time.time()\n",
    "        frequent_itemsets_apriori, rules_apriori = apriori(transactions, items, min_support, min_confidence)\n",
    "        apriori_time = time.time() - start_time\n",
    "        print(f\"Apriori Association Rules Count: {len(rules_apriori)}, Time: {apriori_time:.6f} seconds\")\n",
    "        \n",
    "        # Brute force method\n",
    "        start_time = time.time()\n",
    "        frequent_itemsets_bruteforce = brute_force(transactions, min_support)\n",
    "        rules_bruteforce = generate_association_rules(frequent_itemsets_bruteforce.keys(), transactions, min_confidence)\n",
    "        bruteforce_time = time.time() - start_time\n",
    "        print(f\"Brute Force Association Rules Count: {len(rules_bruteforce)}, Time: {bruteforce_time:.6f} seconds\")\n",
    "\n",
    "# Set minimum support and confidence for comparison\n",
    "min_support = 0.2\n",
    "min_confidence = 0.6\n",
    "\n",
    "# Compare the two algorithms (Apriori and Brute) on all 5 databases\n",
    "compare_algorithms(databases, min_support, min_confidence, items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca14e7ac",
   "metadata": {},
   "source": [
    "### - This function compares the Apriori and Brute Force methods on multiple databases.\n",
    "### - For each database, it prints the number of association rules generated and the time taken by each algorithm.\n",
    "### - The output shows how Apriori is faster while generating the same number of association rules as the Brute Force method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadef8e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8682bb1",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "### In this comparison, both the Apriori algorithm and the Brute Force method generate the same number of association rules for each database, as they are both designed to find all rules that meet the specified minimum support and confidence thresholds. However, the Apriori algorithm significantly outperforms the Brute Force method in terms of execution time due to its optimization of candidate generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
